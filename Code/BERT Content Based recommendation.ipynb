{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Web Mining Test Content Based.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNO//UWdDnorMRBvfv+tSTa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qllb20Ig2wTI","executionInfo":{"status":"ok","timestamp":1623631593512,"user_tz":-120,"elapsed":205,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}},"outputId":"9cea0b9c-e599-474d-f6c0-2fb1e6ace8ab"},"source":["# coding: utf-8\n","\n","# Recommendation systems\n","# A content-based recommendation algorithm.\n","\n","from collections import Counter, defaultdict\n","import math\n","import numpy as np\n","import os\n","import pandas as pd\n","import re\n","from scipy.sparse import csr_matrix\n","import urllib.request\n","import zipfile\n","\n","import nltk\n","from nltk.corpus import stopwords\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","def tokenize_string(my_string):\n","    \"\"\" \n","\tTokenize function.\n","    \"\"\"\n","    return re.findall('[\\w\\-]+', my_string.lower())\n","\n","\n","def tokenize(movies):\n","    \"\"\"\n","    Append a new column to the movies DataFrame with header 'tokens'.\n","    This will contain a list of strings, one per token, extracted\n","    from the 'genre' field of each movie.\n","    Params:\n","      movies...The movies DataFrame\n","    Returns:\n","      The movies DataFrame, augmented to include a new column called 'tokens'.\n","    \"\"\"\n","    ###TODO\n","\n","    movies['tokens'] = [tokenize_string(genre) for genre in movies['netflix_genres']]\n","\n","    return movies\n","\n","\n","def featurize(movies):\n","    \"\"\"\n","    Append a new column to the movies DataFrame with header 'features'.\n","    Each row will contain a csr_matrix of shape (1, num_features). Each\n","    entry in this matrix will contain the tf-idf value of the term.\n","    tfidf(i, d) := tf(i, d) / max_k tf(k, d) * log10(N/df(i))\n","    where:\n","    i is a term\n","    d is a document (movie)\n","    tf(i, d) is the frequency of term i in document d\n","    max_k tf(k, d) is the maximum frequency of any term in document d\n","    N is the number of documents (movies)\n","    df(i) is the number of unique documents containing term i\n","    Params:\n","      movies...The movies DataFrame\n","    Returns:\n","      A tuple containing:\n","      - The movies DataFrame, which has been modified to include a column named 'features'.\n","      - The vocab, a dict from term to int.\n","    \"\"\"\n","    ###TODO\n","\n","    #creating a vocab of all the unique genres\n","    vocab = {movie_tokens:idx for idx, movie_tokens in enumerate(sorted(np.unique(np.concatenate(movies.tokens))))}\n","\n","    # creating df\n","    df = defaultdict(int)\n","    for movie_genre in movies.tokens:\n","        for genre in vocab:\n","            if genre in movie_genre:\n","                df[genre]+=1\n","\n","\n","    #print(sorted(df.items(), key = lambda x: -x[1]))\n","\n","    #for every movie how many times the genre appears\n","\n","    all_csr = []\n","    for idx, movie in enumerate(movies.tokens):\n","        #print(movie)\n","        colmn, data, row = [], [], []\n","        tf = Counter(movie)     # tf\n","        max_k = tf.most_common(1)[0][1]\n","        #print(max_k)# max_k\n","        for genre, freq in tf.items():\n","            if genre in vocab:\n","                #row.append(0)\n","                colmn.append(vocab[genre])\n","                data.append((freq/max_k)*math.log10(len(movies)/df[genre])) # tf-idf\n","                X = csr_matrix((np.asarray(data), (np.zeros(shape=(len(data))), np.asarray(colmn))), shape=(1, len(vocab)))\n","\n","        all_csr.append(X)\n","\n","    movies['features'] = all_csr\n","\n","    #print(movies['features'])\n","\n","    #print(movies.features.head())\n","\n","\n","    return movies, vocab\n","    #pass\n","\n","\n","def train_test_split(ratings):\n","    \"\"\"\n","    Returns a random split of the ratings matrix into a training and testing set.\n","    \"\"\"\n","    test = set(range(len(ratings))[::1000])\n","    train = sorted(set(range(len(ratings))) - test)\n","    test = sorted(test)\n","    return ratings.iloc[train], ratings.iloc[test]\n","\n","\n","\n","def make_predictions(movies, ratings_train, ratings_test):\n","    \"\"\"\n","    Using the ratings in ratings_train, predict the ratings for each\n","    row in ratings_test.\n","    To predict the rating of user u for movie i: Compute the weighted average\n","    rating for every other movie that u has rated.  Restrict this weighted\n","    average to movies that have a positive cosine similarity with movie\n","    i. The weight for movie m corresponds to the cosine similarity between m\n","    and i.\n","    If there are no other movies with positive cosine similarity to use in the\n","    prediction, use the mean rating of the target user in ratings_train as the\n","    prediction.\n","    Params:\n","      movies..........The movies DataFrame.\n","      ratings_train...The subset of ratings used for making predictions. These are the \"historical\" data.\n","      ratings_test....The subset of ratings that need to predicted. These are the \"future\" data.\n","    Returns:\n","      A numpy array containing one predicted rating for each element of ratings_test.\n","    \"\"\"\n","    ###TODO\n","\n","    # for every user in Test Set, get the rating from the Train Set\n","    predictions = []\n","    for row in ratings_test.itertuples():\n","        # got the test userid & test movie_id\n","        #print(\"Getting for\", test_userid, test_movied)\n","        test_userid = getattr(row, 'user_id')\n","        test_movie_id = getattr(row, 'movie_id')\n","        weight_ratings = []\n","        weights = []\n","        target_user_ratings = []\n","        for row in ratings_train.loc[ratings_train.user_id == test_userid, 'movie_id': 'rating'].itertuples():\n","            # got the ratings and movie_id for the test userId\n","            # print(rating_val.movie_id, rating_val.rating)\n","            # print(int(train_user.movie_id), int(test_movie_id))\n","            # print(movies.loc[movies.movie_id == int(train_user.movie_id)].features.values)\n","            # print(movies.loc[movies.movie_id == int(test_movie_id)].features.values)\n","\n","            movie_id = getattr(row, 'movie_id')\n","            rating= getattr(row, 'rating')\n","\n","            cos_sim_weight = cosine_similarity(movies.loc[movies.movie_id == int(movie_id)].features.values[0].toarray(),\n","                                        movies.loc[movies.movie_id == int(test_movie_id)].features.values[0].toarray())\n","            #print(cos_sim_weight)\n","            weight_ratings.append(rating * cos_sim_weight)\n","            weights.append(cos_sim_weight)\n","            target_user_ratings.append(rating)\n","\n","\n","        if np.count_nonzero(weights) > 0:\n","            #weighted_average = np.sum(weight_ratings)/np.sum(weights)\n","            predictions.append(np.sum(weight_ratings)/np.sum(weights))\n","            #print(np.sum(weights))\n","            #print(weighted_average)\n","        else:\n","            predictions.append(ratings_train.loc[ratings_train.user_id == test_userid, 'rating'].mean())\n","            #predictions.append(np.mean(target_user_ratings))\n","\n","            #print(ratings_train.loc[ratings_train.user_id == test_userid, 'rating'].mean())\n","\n","\n","\n","    return np.asarray(predictions)\n","\n","\n","\n","def mean_absolute_error(predictions, ratings_test):\n","    \"\"\"\n","    Return the mean absolute error of the predictions.\n","    \"\"\"\n","    return np.abs(predictions - np.array(ratings_test.rating)).mean()\n","    "],"execution_count":18,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfuFkCHM3J-Y","executionInfo":{"status":"ok","timestamp":1623630711482,"user_tz":-120,"elapsed":16901,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}},"outputId":"6c11b63f-57f0-4752-eb17-b11dc8a796a9"},"source":["# To use it in colab use this code to import the data. \n","# Its necessarc to complet the following steps in advance: \n","# 1. Create a folder in your drive with the Name DMC. \n","# 2. Go to the shard folder 02 Data and do a right click -> Add shortcut to Drive / Drve Verbindung hinzufÃ¼gen -> dann auf den eben erstellen order DMC navigieren\n","from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RxvBVigr3h4n","executionInfo":{"status":"ok","timestamp":1623630742847,"user_tz":-120,"elapsed":2766,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}}},"source":["rawTrain = pd.read_csv(\"/content/drive/My Drive/Web Mining Project/NEW_DATA/Truncated/train_data_ratings.csv\", delimiter=';')\n","rawTest = pd.read_csv(\"/content/drive/My Drive/Web Mining Project/NEW_DATA/Truncated/test_data_ratings.csv\", delimiter=';')\n","rawTrain.drop(['Unnamed: 0'],1,inplace=True)\n","rawTest.drop(['Unnamed: 0'],1,inplace=True)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":97},"id":"mOGfGEYL3jdx","executionInfo":{"status":"ok","timestamp":1623630774473,"user_tz":-120,"elapsed":206,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}},"outputId":"4a5728bd-f850-475b-94dc-81cb80b01f06"},"source":["#Read Extended Data\n","\n","movies = pd.read_csv(\"/content/drive/My Drive/Web Mining Project/NEW_DATA/final_movies_metadata_linked.csv\", delimiter=';')\n","movies.drop(['Unnamed: 0'], axis=1, inplace=True)\n","movies.head(1)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>netflix_id</th>\n","      <th>title</th>\n","      <th>release_year</th>\n","      <th>metadata_id</th>\n","      <th>imdb_id</th>\n","      <th>original_language</th>\n","      <th>overview</th>\n","      <th>tagline</th>\n","      <th>metadata_genres</th>\n","      <th>netflix_genres</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>402</td>\n","      <td>Pan Tadeusz</td>\n","      <td>1999</td>\n","      <td>4966</td>\n","      <td>tt0170351</td>\n","      <td>pl</td>\n","      <td>A grand and patriotic tale of Poland's struggl...</td>\n","      <td>NaN</td>\n","      <td>[{'id': 10752, 'name': 'War'}, {'id': 18, 'nam...</td>\n","      <td>Drama|History|Romance|War</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   netflix_id  ...             netflix_genres\n","0         402  ...  Drama|History|Romance|War\n","\n","[1 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EujFOA6w5GXS","executionInfo":{"status":"ok","timestamp":1623630823354,"user_tz":-120,"elapsed":189,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}},"outputId":"41dcfb9e-42d2-46d5-f991-603ba6d8c0d0"},"source":["movies['netflix_genres']"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0             Drama|History|Romance|War\n","1                    Action|Crime|Drama\n","2                          Comedy|Crime\n","3                       Biography|Drama\n","4       Animation|Comedy|Family|Musical\n","                     ...               \n","8063               Comedy|Drama|Romance\n","8064      Drama|Fantasy|History|Mystery\n","8065               Comedy|Drama|Romance\n","8066        Comedy|Crime|Drama|Thriller\n","8067       Action|Comedy|Crime|Thriller\n","Name: netflix_genres, Length: 8068, dtype: object"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"l0nGzyRb3_yZ","executionInfo":{"status":"ok","timestamp":1623630827698,"user_tz":-120,"elapsed":257,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}}},"source":["lemmatizer = WordNetLemmatizer()\n","\n","def lemmatize(words):\n","    a = words.split(\" \")\n","    res = []\n","    for i in a: \n","        res.append(lemmatizer.lemmatize(i))\n","    return \" \".join(res)\n","\n","def make_lower_case(text):\n","    return text.lower()\n","\n","def remove_stop_words(text):\n","    text = text.split()\n","    stops1 = set(stopwords.words(\"english\"))\n","    text = [w for w in text if not w in stops1]\n","    \n","    stops2 = set(stopwords.words(\"german\"))\n","    text = [w for w in text if not w in stops2]\n","\n","    stops3 = set(stopwords.words(\"french\"))\n","    text = [w for w in text if not w in stops3]\n","    text = \" \".join(text)\n","    \n","    return text\n","\n","def remove_punctuation(sentence): \n","    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n","    new_words = tokenizer.tokenize(sentence)\n","\n","    return \" \".join(new_words)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"s6oU3K6j5y0j","executionInfo":{"status":"ok","timestamp":1623630829799,"user_tz":-120,"elapsed":179,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}}},"source":["movies['netflix_genres'] = movies['netflix_genres'].astype(str)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"fu8p51i_4SPR","executionInfo":{"status":"ok","timestamp":1623596696506,"user_tz":-120,"elapsed":5892,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}}},"source":["movies['netflix_genres'] = movies['netflix_genres'].map(lambda x: x.replace(\"|\", \" \"))\n","movies['netflix_genres'] = movies['netflix_genres'].apply(remove_punctuation)\n","movies['netflix_genres'] = movies['netflix_genres'].apply(make_lower_case)\n","movies['netflix_genres'] = movies['netflix_genres'].apply(lambda x: ' '.join(x.split()))\n","movies['netflix_genres'] = movies['netflix_genres'].apply(lemmatize)\n","movies['netflix_genres'] = movies['netflix_genres'].apply(remove_stop_words)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"lqRo0DkM6wXS","executionInfo":{"status":"ok","timestamp":1623630831944,"user_tz":-120,"elapsed":228,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}}},"source":["movies['movie_id'] = movies['netflix_id']"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPGJDGZY3Fbh","executionInfo":{"status":"ok","timestamp":1623630838220,"user_tz":-120,"elapsed":5451,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}},"outputId":"4e572219-b281-4726-8b36-2fa60f335deb"},"source":["movies = tokenize(movies)\n","movies, vocab = featurize(movies)\n","print('vocab:')\n","print(sorted(vocab.items())[:10])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["vocab:\n","[('action', 0), ('adventure', 1), ('animation', 2), ('biography', 3), ('comedy', 4), ('crime', 5), ('documentary', 6), ('drama', 7), ('family', 8), ('fantasy', 9)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hll6qqd43IRB","executionInfo":{"status":"ok","timestamp":1623630843323,"user_tz":-120,"elapsed":212,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}},"outputId":"5119764d-07b7-47b5-b572-20b335542860"},"source":["\n","print('%d training ratings; %d testing ratings' % (len(rawTrain), len(rawTest)))\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["3199119 training ratings; 1066374 testing ratings\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cs4xykxB9vX8","executionInfo":{"status":"ok","timestamp":1623597774005,"user_tz":-120,"elapsed":378,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}}},"source":["rawTest = rawTest.sort_values('user_id')"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"pqn8222N9_rL","executionInfo":{"status":"ok","timestamp":1623630894132,"user_tz":-120,"elapsed":202,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}},"outputId":"6ecf1476-0203-4949-cf5f-0641db9041fc"},"source":["rawTest.head(10)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>movie_id</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2059086</td>\n","      <td>758</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>697601</td>\n","      <td>1975</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>396326</td>\n","      <td>1406</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2254919</td>\n","      <td>571</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>554424</td>\n","      <td>257</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1093947</td>\n","      <td>1144</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>649585</td>\n","      <td>919</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1906979</td>\n","      <td>1518</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>353309</td>\n","      <td>334</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1954166</td>\n","      <td>312</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id  movie_id  rating\n","0  2059086       758       3\n","1   697601      1975       2\n","2   396326      1406       3\n","3  2254919       571       4\n","4   554424       257       5\n","5  1093947      1144       1\n","6   649585       919       1\n","7  1906979      1518       2\n","8   353309       334       3\n","9  1954166       312       3"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"ZhNP94696niy","executionInfo":{"status":"ok","timestamp":1623631694814,"user_tz":-120,"elapsed":95027,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}}},"source":["predictions = make_predictions(movies, rawTrain, rawTest.head(1000))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zvcsJt7o7B2L","executionInfo":{"status":"ok","timestamp":1623630562924,"user_tz":-120,"elapsed":295,"user":{"displayName":"Rahul Joshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjloI2zvVyxjd528d138bhcRwh1OImwjC7Pfa-oSg=s64","userId":"14357237801485708781"}},"outputId":"7e3208b6-ab12-4417-d9e3-0aef0b6d7fa3"},"source":["predictions"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3.3953991 , 3.55252652, 3.29428866, 3.40172428, 3.40172428,\n","       3.32541796, 3.46749413, 3.51621897, 3.56020053, 3.28497504])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"6lnoq9EF6rZa"},"source":["print('error=%f' % mean_absolute_error(predictions, rawTest))\n","print(predictions[:10])"],"execution_count":null,"outputs":[]}]}